{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maradeben/oop-tutorial-mit/blob/main/Data_science_notebook_mit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Complete Companion Guide for the Healthcare AI & Data Literacy Challenge**\n",
        "\n",
        "![welcome](https://imgs.search.brave.com/6AUCT3KxHZPH8bXlACEFDmV5kIHmrWvE5uBt4H4GtSA/rs:fit:500:0:1:0/g:ce/aHR0cHM6Ly90NC5m/dGNkbi5uZXQvanBn/LzEyLzQ3LzU1LzU5/LzM2MF9GXzEyNDc1/NTU5MDNfMTN6dW4y/Nmt5d0dsR1Q2SmFY/UVUwTHB1NFJGRDhu/YksuanBn)\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Welcome to the Healthcare AI & Data Literacy Challenge\\! Think of this guide as a bridge between your DataCamp courses and your own clinical world. Its goal is to translate the core ideas of data science into practical, relatable healthcare scenarios and then show you how to bring them to life with Python.\n",
        "\n",
        "We'll start with the \"why\" and the \"what\" in Part I, and then Part II will guide you through the \"how\" with hands-on code.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Part I: Understanding Data Science in a Clinical Context**\n",
        "\n",
        "#### **What Exactly is Data Science? 🧬**\n",
        "\n",
        "At its heart, data science is the art of finding meaningful patterns in data to make better predictions. In a hospital, you're surrounded by an ocean of data: Electronic Health Records (EHRs), lab results, medical images, and patient feedback. Data science provides the tools to transform this raw information into life-saving insights.\n",
        "\n",
        "  * **Clinical Analogy:** Imagine you could analyze the records of every patient who ever developed sepsis in your hospital. By identifying subtle, early warning signs that humans might miss, you could build a system that flags at-risk patients the moment they're admitted. That's the power of data science—turning historical data into a proactive tool for patient care.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **The Data Science Team in a Hospital**\n",
        "\n",
        "Data science isn't a one-person job; it's a team effort, much like a clinical care team.\n",
        "\n",
        "  * **The Data Engineer (The Architect):** This is the person who builds the hospital's data plumbing. They create the systems (**pipelines**) that safely and efficiently collect data from the EHR, pharmacy, and lab systems, ensuring it's clean and organized for everyone else to use.\n",
        "  * **The Data Analyst (The Storyteller):** The analyst takes the organized data and tells a story with it. They create the charts and dashboards you might see in a hospital command center—like a real-time graph of ER wait times—that help administrators understand what's happening *right now*.\n",
        "  * **The Data Scientist (The Forecaster):** The scientist uses advanced statistics and AI to predict the future. They build the models that can forecast next month's ICU demand or analyze a tumor's genetic data to recommend a personalized treatment plan.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **Medical Data: Sources and Types**\n",
        "\n",
        "  * **Data Sources**:\n",
        "      * **Internal Data**: Your hospital's own information, like EHRs, billing records, and patient satisfaction surveys.\n",
        "      * **Open Data**: Freely available public datasets from organizations like the World Health Organization (WHO) or research databases like The Cancer Genome Atlas.\n",
        "      * **APIs (Application Programming Interfaces)**: Think of these as secure data taps. They allow systems to get real-time data from other sources, like a patient's continuous glucose monitor or a public health database.\n",
        "  * **Data Types**:\n",
        "      * **Quantitative (Numerical)**: Anything you can measure with a number, like a patient's heart rate, blood pressure, or creatinine level.\n",
        "      * **Qualitative (Categorical)**: Descriptive information, like a doctor's clinical notes, a diagnosis code, or patient-reported symptoms.\n",
        "      * **Other Forms**: Healthcare is full of complex data, including **images** (X-rays, CT scans), **text** (clinical notes, research papers), and **geospatial data** (for mapping disease outbreaks).\n",
        "\n",
        "-----\n",
        "\n",
        "#### **The Data Science Workflow: A Step-by-Step Clinical Project**\n",
        "\n",
        "1.  **Data Collection & Storage**: First, data is gathered from all sources. Structured data (like lab values) is often stored in **Relational Databases**, while unstructured data (like doctor's notes) goes into **Document Databases**.\n",
        "2.  **Data Preparation (The \"Scrub-In\")**: Real-world clinical data is messy. Just as a surgeon scrubs in before a procedure, a data scientist must \"clean\" the data. This means correcting typos, standardizing units, and addressing missing values.\n",
        "3.  **Exploration & Visualization (EDA)**: This is the diagnostic phase. Before building a model, you must explore the data to understand its patterns and limitations. This involves creating charts and summary statistics. A **dashboard** is a common tool here, providing a high-level view of key hospital metrics.\n",
        "4.  **Experimentation & Prediction**: This is where you generate your key findings.\n",
        "      * **A/B Testing**: This is the data science version of a Randomized Controlled Trial (RCT). For instance, a clinic could test two different appointment reminders to see which one reduces no-shows more effectively.\n",
        "      * **Time Series Forecasting**: Using past data to predict the future. A classic example is forecasting seasonal flu cases to ensure proper staffing and supplies.\n",
        "      * **Supervised Machine Learning**: Training an AI model on labeled data. You could feed a model thousands of retinal scans labeled \"diabetic retinopathy\" or \"healthy\" to teach it to diagnose the condition on its own.\n",
        "      * **Unsupervised Machine Learning**: Finding hidden patterns in unlabeled data. This can be used to discover new patient subgroups (phenotypes) who might respond differently to a medication, even if you didn't know those groups existed beforehand.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **Frontiers in Healthcare AI**\n",
        "\n",
        "  * **Advanced Predictive Modeling**: Beyond basic models, data scientists often compare powerful algorithms like **XGBoost** and **Random Forests** to find the most accurate one. This requires careful data prep, including **scaling** features so the model treats them equally.\n",
        "  * **Explainable AI (XAI)**: A major goal in clinical AI is avoiding the \"black box\" problem. Tools like **SHAP (SHapley Additive exPlanations)** help explain *why* a model made a decision—for example, by showing that a high HbA1C value was the main reason it flagged a patient for diabetes risk. For image-based models, techniques like **Grad-CAM** create heatmaps that highlight which parts of an image (like a specific region on a chest X-ray) the model focused on to make its diagnosis. These methods are crucial for building trust and ensuring clinical adoption.\n",
        "  * **Natural Language Processing (NLP)**: This is AI that understands human language. In healthcare, it's used for **sentiment analysis** (e.g., is a drug review positive or negative?) and creating advanced visualizations with tools like **Scattertext** to explore the relationships between medications and the conditions they treat.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Part II: Applying Data Science in Python - A Coding Reference**\n",
        "\n",
        "This section serves as a practical, hands-on guide to the coding concepts discussed in the course materials. It is designed to be followed in a Google Colab or Jupyter Notebook environment.\n",
        "\n",
        "#### **1. Foundational Coding Concepts**\n",
        "\n",
        "These are the essential building blocks for working with data in Python.\n",
        "\n",
        "##### **A. Setting Up and Loading Data**\n",
        "\n",
        "First, we import the necessary libraries and create a simulated patient DataFrame using **pandas**. In a real project, you would typically load this data from a CSV file."
      ],
      "metadata": {
        "id": "-jNVDeYJdEm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Foundational Coding Concepts 🐍\n",
        "\n",
        "These concepts cover the basics of loading, inspecting, filtering, and visualizing data, primarily using the **pandas** and **matplotlib** libraries.\n",
        "\n",
        "### Data Loading and Inspection (pandas)\n",
        "* **`pd.read_csv()`**: Loads data from a CSV file into a DataFrame.\n",
        "* **`.head()`**: Displays the first few rows of a DataFrame to quickly inspect the data.\n",
        "* **`.info()`**: Provides a technical summary of a DataFrame, including data types and non-null value counts for each column.\n",
        "\n",
        "### Data Manipulation and Selection (pandas)\n",
        "* **Column Selection**: Accessing a specific column of data using bracket notation (e.g., `df['hba1c']`) or dot notation (e.g., `df.hba1c`).\n",
        "* **Logical Filtering**: Selecting rows that meet a specific condition (e.g., `patient_df[patient_df['hba1c'] >= 6.5]`).\n",
        "\n",
        "### Data Visualization (matplotlib) 📊\n",
        "* **`plt.scatter()`**: Creates a scatter plot to visualize the relationship between two numerical variables.\n",
        "* **`plt.hist()`**: Creates a histogram to show the distribution of a single numerical variable.\n",
        "* **`plt.bar()`**: Creates a bar chart to compare numerical values across different categories.\n",
        "* **`plt.title()`**, **`plt.xlabel()`**, **`plt.ylabel()`**: Functions used to add a title and axis labels to a plot for clarity.\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "OcQf0ox2e3-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# Create a dictionary with our simulated patient data relevant to Type II Diabetes\n",
        "data = {\n",
        "    'age': [50, 65, 45, 72, 38, 55, 61, 48, 79, 31, 58, 68],\n",
        "    'bmi': [30.1, 33.5, 28.0, 35.2, 25.5, 29.8, 31.0, 27.3, 36.1, 23.1, 32.4, 34.0],\n",
        "    'hba1c': [7.1, 8.2, 5.5, 9.1, 5.1, 6.9, 7.5, 6.0, 9.5, 4.9, 7.8, 8.5],\n",
        "    'blood_glucose_mg_dl': [155, 180, 105, 210, 95, 140, 165, 120, 230, 88, 170, 190],\n",
        "    'has_diabetes': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n",
        "}\n",
        "patient_df = pd.DataFrame(data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "U1qWZJU0dEm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **B. Data Inspection and Selection**\n",
        "\n",
        "Before analysis, we inspect our data with `.head()` to see the first few rows and `.info()` for a technical summary. We can then select specific columns for analysis or filter rows based on logical conditions."
      ],
      "metadata": {
        "id": "EDBT53X1dEm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows and technical info\n",
        "print(\"First 5 patient records:\")\n",
        "print(patient_df.head())\n",
        "print(\"\\nTechnical information about the dataset:\")\n",
        "patient_df.info()\n",
        "\n",
        "# Filter for patients with HbA1c >= 6.5%, a diagnostic criterion for diabetes\n",
        "diabetic_patients = patient_df[patient_df['hba1c'] >= 6.5]\n",
        "print(\"\\nPatients meeting HbA1c criteria for diabetes:\")\n",
        "print(diabetic_patients)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "AIlF2apsdEm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **C. Basic Data Visualization**\n",
        "\n",
        "Visualizations help uncover insights. A **scatter plot** can show relationships between two numerical variables, a **histogram** shows the distribution of a single variable, and a **bar chart** compares values across categories."
      ],
      "metadata": {
        "id": "AASDrsM3dEm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of BMI vs. HbA1c\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.scatter(patient_df['bmi'], patient_df['hba1c'], color='red')\n",
        "plt.title('Patient BMI vs. HbA1c Level')\n",
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Glycated Hemoglobin (HbA1c %)')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "clqq9A9rdEm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Advanced Coding Concepts**\n",
        "\n",
        "This reference covers a more complete machine learning workflow, from advanced preprocessing to model explanation and NLP.\n",
        "\n",
        "  * **Data Cleaning and Preprocessing**\n",
        "      * `.str.strip()`: A pandas method used to remove leading and trailing spaces from text data, which is useful for cleaning inconsistent labels.\n",
        "      * `LabelEncoder`: A tool from **scikit-learn** to convert categorical text labels (e.g., \"Male\", \"Female\") into numerical values that can be used by a model.\n",
        "      * `MinMaxScaler`: A **scikit-learn** tool that scales all numerical features to a common range (typically 0 to 1), which improves the performance of many machine learning models.\n",
        "  * **Exploratory Data Analysis (EDA)**\n",
        "      * **Seaborn Heatmap**: A visualization used to show the correlation matrix of numerical features, making it easy to spot relationships between variables.\n",
        "  * **Machine Learning Modeling**\n",
        "      * `train_test_split`: A function from **scikit-learn** to divide a dataset into training and testing sets, which is essential for evaluating a model's performance on unseen data.\n",
        "      * **Model Training**: Implementing and training various classification algorithms, such as Logistic Regression, K-Nearest-Neighbor, and a powerful algorithm called **XGBoost Classifier**.\n",
        "      * `classification_report`: A **scikit-learn** function that provides key evaluation metrics like precision, recall, and F1-score for each class in a classification problem.\n",
        "      * `confusion_matrix`: A **scikit-learn** tool that gives a detailed breakdown of a model's correct and incorrect predictions for each class.\n",
        "  * **Model Explainability and NLP**\n",
        "      * **SHAP (SHapley Additive exPlanations)**: A library used to explain the output of any machine learning model by quantifying the contribution of each feature to a specific prediction.\n",
        "      * **Hugging Face `transformers`**: A powerful library for NLP tasks. It can be used to load pre-trained AI models to perform **sentiment analysis** on text data like drug reviews.\n",
        "      * **Word Clouds**: A visualization technique used to display the most frequent words in a body of text, helping to quickly identify prominent medications or conditions.\n",
        "      * **Scattertext**: A Python library for creating interactive visualizations that reveal relationships and distinguishing terms between different categories of text data.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Detailed Healthcare Use Cases in Practice**\n",
        "\n",
        "#### **Use Case: Diabetes Prediction using Machine Learning 🩺**\n",
        "\n",
        "This use case demonstrates how to build a model to predict Type II diabetes using a patient dataset. Diabetes is a chronic disease characterized by high blood sugar, and its diagnosis can be based on metrics like fasting plasma glucose, oral glucose tolerance tests, or an HbA1C value of 6.5% or greater.\n",
        "\n",
        "The machine learning workflow involves several key steps:\n",
        "\n",
        "  * **Data Preprocessing**: The data is loaded into a pandas DataFrame. Initial cleaning includes fixing inconsistent labels by stripping extra spaces from values. Categorical data like gender and age ranges are converted into numerical codes using `LabelEncoder` from scikit-learn. Numerical features, which are on different scales, are normalized to a range between zero and one using `MinMaxScaler`.\n",
        "  * **Model Training and Comparison**: The dataset is split, with 20% reserved for testing. Seven different machine learning algorithms, including Logistic Regression, K-Nearest-Neighbor, and XGBoost Classifier, are compared using cross-validation to find the best performer. In this scenario, **XGBoost** achieves the highest accuracy score.\n",
        "  * **Evaluation**: The trained XGBoost model achieves a high accuracy score on the test set. The model's performance is further detailed using a classification report, which provides precision, recall, and F1-scores, and a confusion matrix that compares the true labels versus the predicted labels.\n",
        "  * **Explainability**: To understand the model's decisions, **SHAP (SHapley Additive exPlanations)** is used. This technique quantifies how much each feature contributed to the prediction, confirming that HbA1C and BMI were key parameters the model learned for diagnosing diabetes, which aligns with clinical knowledge.\n",
        "\n",
        "[Image of a machine learning workflow diagram]\n",
        "\n",
        "-----\n",
        "\n",
        "#### **Use Case: Sentiment Analysis of Drug Reviews 📝**\n",
        "\n",
        "This use case applies sentiment analysis to a drug review dataset to classify patient feedback as positive, negative, or neutral.\n",
        "\n",
        "The process uses **pre-trained transformer models** from the Hugging Face library to analyze the text.\n",
        "\n",
        "  * **Model Comparison**: Three different models (`bio_clinicbert`, `rubert_classifier`, and `roberta_classifier`) are compared on sample reviews.\n",
        "  * **Application**: After comparison, the best-performing models are applied to the full dataset of reviews. The output for each review includes a sentiment label (e.g., positive, negative) and a confidence score for that prediction. An interesting next step is to compare the model's predicted sentiment with the numerical ratings provided by the original reviewers.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **Use Case: Text Visualization for Diseases and Medications 📊**\n",
        "\n",
        "This use case focuses on using text visualization as a tool for exploratory data analysis to understand the complex relationships between diseases and medications. The same medication can often treat multiple diseases, and one disease can be treated by many medications.\n",
        "\n",
        "Two primary visualization techniques are used:\n",
        "\n",
        "  * **Word Clouds**: Word clouds are generated to quickly visualize the most prominent medications and conditions within the dataset. For example, the visualization might show that medications related to birth control and anxiolytics are highly frequent, as are conditions like depression and high blood pressure.\n",
        "  * **Scattertext**: This Python library is used to create interactive visualizations that reveal relationships between text data. It can generate a plot showing which conditions are most frequently associated with a specific medication. For example, it can confirm that Metoclopramide is strongly associated with conditions like \"Migraine\" and \"nausea,\" aligning with its clinical use as an antiemetic."
      ],
      "metadata": {
        "id": "Vn8y_WxTdEm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specialty-Specific Module: Application Examples\n",
        "\n",
        "Nursing:\n",
        "\n",
        "Data Cleaning: Standardizing notes on patient fall risk assessments.\n",
        "\n",
        "Dashboarding: Creating a ward dashboard to track patient-to-nurse ratios and workloads.\n",
        "\n",
        "General/Family Medicine:\n",
        "\n",
        "Supervised ML: Building a model to predict a patient's 10-year risk of cardiovascular disease based on their current health metrics.\n",
        "\n",
        "Data Exploration: Analyzing patient demographics to identify populations that are overdue for preventative screenings.\n",
        "\n",
        "Surgery:\n",
        "\n",
        "Time Series Forecasting: Predicting the demand for specific surgical instruments to optimize inventory.\n",
        "\n",
        "A/B Testing: Comparing post-operative pain scores between two different pain management protocols.\n",
        "\n",
        "Obstetrics and Gynecology:\n",
        "\n",
        "Supervised ML: Developing an algorithm to detect signs of pre-eclampsia from routine monitoring data.\n",
        "\n",
        "Data Visualization: Plotting fetal growth charts against population averages.\n",
        "\n",
        "Pediatrics:\n",
        "\n",
        "Time Series Forecasting: Predicting seasonal peaks in RSV infections to staff clinics appropriately.\n",
        "\n",
        "Clustering: Grouping children with developmental delays based on symptom profiles to identify distinct phenotypes.\n",
        "\n",
        "Anesthesiology:\n",
        "\n",
        "Data Pipelines: Creating real-time data streams from operating room monitors into a central research database.\n",
        "\n",
        "Supervised ML: Predicting which patients are most likely to experience post-operative nausea.\n",
        "\n",
        "Pharmacy:\n",
        "\n",
        "Data Cleaning: Standardizing medication names from different EHR systems (e.g., \"Tylenol\" vs. \"Acetaminophen\").\n",
        "\n",
        "A/B Testing: Testing two different patient-facing leaflets about a new medication to see which one improves adherence.\n",
        "\n",
        "Medical Laboratory Science:\n",
        "\n",
        "Data Cleaning: Identifying and flagging outlier or erroneous lab results automatically.\n",
        "\n",
        "Time Series Forecasting: Predicting the demand for specific lab reagents to prevent shortages.\n",
        "\n",
        "Dentistry:\n",
        "\n",
        "Supervised ML: Training a model on X-rays to automatically detect and flag potential cavities for review.\n",
        "\n",
        "Data Exploration: Analyzing patient records to find correlations between oral hygiene habits and periodontal disease.\n",
        "\n",
        "Radiology/Medical Imaging:\n",
        "\n",
        "Supervised ML: Building a model to classify chest X-rays for signs of pneumonia.\n",
        "\n",
        "Clustering: Grouping brain MRI scans to identify different patterns of tumor growth.\n",
        "\n",
        "Oncology:\n",
        "\n",
        "Clustering: Analyzing genomic data from tumors to identify distinct molecular subtypes that respond differently to therapies.\n",
        "\n",
        "Supervised ML: Predicting patient response to a specific chemotherapy regimen.\n",
        "\n",
        "Cardiology:\n",
        "\n",
        "Time Series Forecasting: Analyzing ECG data to predict the onset of atrial fibrillation.\n",
        "\n",
        "Data Visualization: Creating scatter plots to visualize the relationship between blood pressure and age.\n",
        "\n",
        "Public Health:\n",
        "\n",
        "Geospatial Data Analysis: Mapping COVID-19 cases to identify hotspots and inform public policy.\n",
        "\n",
        "Time Series Forecasting: Predicting the spread of a seasonal flu outbreak.\n",
        "\n",
        "Community Health:\n",
        "\n",
        "Data Exploration: Analyzing local data to identify neighborhoods with low access to healthcare services.\n",
        "\n",
        "Dashboarding: Creating a community dashboard showing vaccination rates by zip code.\n",
        "\n",
        "Mental Health:\n",
        "\n",
        "Supervised ML (NLP): Analyzing text from therapy session transcripts to predict patient outcomes.\n",
        "\n",
        "Clustering: Grouping patients based on their responses to psychiatric questionnaires to identify different depression subtypes.\n",
        "\n",
        "Biomedical Engineering:\n",
        "\n",
        "Data Pipelines: Building systems to stream data from new medical devices for clinical trials.\n",
        "\n",
        "Time Series Analysis: Analyzing sensor data from a prosthetic limb to improve its performance.\n",
        "\n",
        "Physiotherapy:\n",
        "\n",
        "Time Series Analysis: Tracking a patient's range of motion over time using wearable sensors.\n",
        "\n",
        "Data Visualization: Plotting a patient's recovery progress against their rehabilitation goals.\n",
        "\n",
        "Nutrition and Dietetics:\n",
        "\n",
        "Clustering: Grouping patients based on their dietary logs to identify common eating patterns.\n",
        "\n",
        "A/B Testing: Comparing weight loss outcomes between two different diet plans.\n",
        "\n",
        "Radiography:\n",
        "\n",
        "Supervised ML: Developing AI tools to automatically position patients for optimal X-ray imaging.\n",
        "\n",
        "Data Exploration: Analyzing image metadata to identify factors that contribute to low-quality scans.\n",
        "\n",
        "Physiology:\n",
        "\n",
        "Time Series Analysis: Studying high-frequency data from physiological experiments to understand cellular responses.\n",
        "\n",
        "Data Visualization: Plotting the relationship between oxygen saturation and heart rate during exercise.\n",
        "\n",
        "Optometry:\n",
        "\n",
        "Supervised ML: Training an algorithm on retinal fundus images to screen for glaucoma.\n",
        "\n",
        "Data Exploration: Analyzing patient data to find risk factors for age-related macular degeneration.\n",
        "\n",
        "Environmental Health Science:\n",
        "\n",
        "Geospatial Data Analysis: Mapping the correlation between air pollution levels and hospital admissions for asthma.\n",
        "\n",
        "Data Exploration: Analyzing data to link exposure to certain chemicals with health outcomes.\n",
        "\n",
        "Health Information Management:\n",
        "\n",
        "Data Cleaning: Leading projects to de-duplicate patient records and ensure data integrity in the EHR.\n",
        "\n",
        "Data Pipelines: Overseeing the flow of data between different hospital IT systems.\n",
        "\n",
        "Occupational Therapy:\n",
        "\n",
        "Data Visualization: Charting a patient's progress in activities of daily living (ADLs) over time.\n",
        "\n",
        "Time Series Analysis: Using sensor data to analyze the ergonomics of a worker's movements.\n",
        "\n",
        "Medical Physics:\n",
        "\n",
        "Supervised ML: Building models to optimize radiation therapy plans for cancer patients.\n",
        "\n",
        "Image Data Analysis: Developing new algorithms to improve the quality of MRI scans."
      ],
      "metadata": {
        "id": "zg9LZF4rtwBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part II: Advanced Use Cases & End-to-End Workflows\n",
        "Introduction\n",
        "\n",
        "Welcome to the advanced section! In Part I, we covered the basic building blocks. Here, we'll walk through more complete, real-world workflows that mirror the process a data scientist in a hospital or research center would follow. We will explore three specific use cases: building a diabetes prediction model, analyzing sentiment in drug reviews, and visualizing relationships in text data.\n",
        "\n",
        "Use Case 1: End-to-End Diabetes Prediction Model\n",
        "\n",
        "Our goal is to build a machine learning model that can predict whether a patient has Type II diabetes based on their clinical data. We will go through a more realistic workflow that includes data cleaning, preprocessing, model training, and a crucial final step: model explanation.\n",
        "\n",
        "\n",
        "\n",
        "1. Advanced Data Cleaning & Preprocessing\n",
        "\n",
        "Real-world data often has formatting issues. For instance, categorical data might have extra spaces that need to be removed. Furthermore, most machine learning models require all input to be numerical.\n",
        "\n",
        "\n",
        "Label Encoding: We convert categorical columns (like 'gender') into numbers.\n",
        "\n",
        "\n",
        "Scaling: Clinical measurements are on different scales (e.g., BMI vs. HbA1C). We use a\n",
        "\n",
        "MinMaxScaler to transform all numerical features to a common range of 0 to 1, which helps the model perform better."
      ],
      "metadata": {
        "id": "559BvB4Yu9wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a conceptual code block to illustrate the steps.\n",
        "# In a real scenario, you'd have more data. We'll use our small DataFrame to demonstrate.\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# --- Cleaning ---\n",
        "# Imagine a 'gender' column was added with extra spaces\n",
        "patient_df['gender'] = [' Male', 'Female', 'Female ', 'Male', 'Female', 'Male', 'Male', 'Female', 'Female', ' Male', 'Male', 'Female']\n",
        "print(\"Gender before cleaning:\\n\", patient_df['gender'].unique())\n",
        "patient_df['gender'] = patient_df['gender'].str.strip()\n",
        "print(\"Gender after cleaning:\\n\", patient_df['gender'].unique())\n",
        "\n",
        "# --- Label Encoding ---\n",
        "le = LabelEncoder()\n",
        "patient_df['gender_encoded'] = le.fit_transform(patient_df['gender'])\n",
        "print(\"\\nDataFrame with encoded gender:\")\n",
        "print(patient_df.head())\n",
        "\n",
        "# --- Scaling ---\n",
        "# Select only numerical columns for scaling\n",
        "numerical_cols = ['age', 'bmi', 'hba1c', 'blood_glucose_mg_dl']\n",
        "scaler = MinMaxScaler()\n",
        "patient_df[numerical_cols] = scaler.fit_transform(patient_df[numerical_cols])\n",
        "print(\"\\nDataFrame after scaling numerical features:\")\n",
        "print(patient_df.head())"
      ],
      "metadata": {
        "id": "k78bMeghu856"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. EDA with a Correlation Heatmap\n",
        "A heatmap is a great way to quickly see which variables are correlated. Lighter shades indicate a stronger positive correlation. For example, we'd expect HbA1C and BMI to be correlated"
      ],
      "metadata": {
        "id": "cc6KEo9NvS6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Re-create a simple numerical DataFrame for the heatmap\n",
        "data = {'age': [50, 65, 45, 72], 'bmi': [30.1, 33.5, 28.0, 35.2], 'hba1c': [7.1, 8.2, 5.5, 9.1], 'blood_glucose_mg_dl': [155, 180, 105, 210]}\n",
        "corr_df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = corr_df.corr()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap of Clinical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3iaxoCOHvYpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model Training & Evaluation\n",
        "We'll now train an\n",
        "\n",
        "XGBoost Classifier, a powerful and popular algorithm that performed best in the example analysis. We first split our data into a training set (for the model to learn from) and a test set (to evaluate its performance on unseen data)"
      ],
      "metadata": {
        "id": "W43Gn-sPvZa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a conceptual code block. XGBoost requires installation.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Define features (X) and the target label (y)\n",
        "features = ['age', 'bmi', 'hba1c', 'blood_glucose_mg_dl', 'gender_encoded']\n",
        "target = 'has_diabetes'\n",
        "\n",
        "X = patient_df[features]\n",
        "y = patient_df[target]\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"--- Model Evaluation ---\")\n",
        "# A confusion matrix shows a comparison of true vs. predicted labels [cite: 56]\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "# A classification report shows precision, recall, and F1-score for each class [cite: 55]\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "yBBR1k_0vddj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Case 2: Sentiment Analysis on Drug Reviews\n",
        "\n",
        "Analyzing patient reviews can provide valuable insights. Using pre-trained\n",
        "\n",
        "transformer models from libraries like Hugging Face, we can perform sentiment analysis to automatically classify text as positive, negative, or neutral"
      ],
      "metadata": {
        "id": "aPuUiARZvpC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code requires installing the transformers library: !pip install transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a pre-trained sentiment analysis model\n",
        "sentiment_classifier = pipeline('sentiment-analysis')\n",
        "\n",
        "# Example drug review\n",
        "review = \"I was hesitant at first, but this medicine has completely changed my life for the better. I have no side effects.\"\n",
        "\n",
        "# Get the sentiment prediction\n",
        "result = sentiment_classifier(review)\n",
        "print(f\"Review: '{review}'\")\n",
        "print(f\"Predicted Sentiment: {result}\")"
      ],
      "metadata": {
        "id": "AHyTWXF8vqjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Case 3: Visualizing Text Data Relationships\n",
        "\n",
        "When dealing with thousands of reviews, we need ways to explore the data quickly.\n",
        "\n",
        "1. Word Clouds\n",
        "A word cloud is a simple yet powerful visualization where the size of each word is proportional to its frequency in the text. This can help us quickly identify the most commonly discussed medications or conditions in a large dataset."
      ],
      "metadata": {
        "id": "oNZFWn2RvsuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code requires installing the wordcloud library: !pip install wordcloud\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Sample text data of conditions mentioned in reviews\n",
        "text_data = \"birth control pain depression anxiety high blood pressure pain birth control acne pain depression birth control\"\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GPlqgbN-vv2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}